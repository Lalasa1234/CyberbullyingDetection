# CyberbullyingDetection
Finetuning the Large Language Model to predict whether the tweet is toxic or not

### Problem Statement
Cyberbullying involves posting and sharing false, private, negative, or harmful information about a victim. In today's digital world, we frequently encounter instances where individuals are targeted online. We seek a software solution to mitigate such bullying and harassment in cyberspace. The solution should work on 'X' platform and detect the toxicity of tweets so that the appropriate authorities take the right action.
